import numpy as np
import pandas as pd 
import rasterio
from pyproj import CRS, Transformer
from pyproj.enums import TransformDirection
import xarray as xr
import verde as vd
import harmonica as hm
import itertools
import matplotlib.pyplot as plt
import rioxarray 

# Defining the custom projection
def geographic2projected(crs_input, geoCoords):
    # Ensure input arrays are numpy arrays.
    lat = np.asarray(geoCoords[0])
    lon = np.asarray(geoCoords[1])
    
    # Calculate the median longitude to center the projection.
    median_lon = np.median(lon)
    
    # Define a custom Transverse Mercator projection centered at the median longitude.
    crs_custom = CRS.from_string(f"+proj=tmerc +lon_0={median_lon} +datum=WGS84")
    
    # Create the input CRS object.
    input_crs = CRS.from_user_input(crs_input)
    
    # Create a transformer from the input CRS to the custom projection.
    transformer = Transformer.from_crs(input_crs, crs_custom, always_xy=True)
    
    # Perform a vectorized transformation.
    x, y = transformer.transform(lon, lat)
    projCoords = np.array([x, y])
    
    return crs_custom, projCoords

# Converting the TIFF files to DataFrame
def tiff_to_dataframe(elevation_1_file, elevation_2_file, gravity_1_file, gravity_2_file):
    # Open the Maciços's Elevation Files
    with rasterio.open(elevation_1_file) as src_elev_1:
        elev_arr1 = src_elev_1.read(1)
        transform_elev1 = src_elev_1.transform
        height_1, width_1 = elev_arr1.shape

    # Open tbe Recorte's Elevation File
    with rasterio.open(elevation_2_file) as src_elev_2:
        elev_arr2 = src_elev_2.read(1)
        transform_elev2 = src_elev_2.transform
        height_2, width_2 = elev_arr2.shape

    # Open the Maciço's Gravity File
    with rasterio.open(gravity_1_file) as src_grav1:
        grav_arr1 = src_grav1.read(1)
        transform_grav1 = src_grav1.transform
        height_g1, width_g1 = grav_arr1.shape

    # Open the Recorte's Gravity File
    with rasterio.open(gravity_2_file) as src_grav2:
        grav_arr2 = src_grav2.read(1)
        transform_grav2 = src_grav2.transform
        height_g2, width_g2 = grav_arr2.shape

    lat_macico = []
    latitude_2 = []
    lon_macico = []
    longitude_2 = []
    elevation_1_list = [] 
    elevation_2_list = []  
    gravity_1_list = []
    gravity_2_list = []

    # Loop fot the first chunk (Maciço)
    for row in range(height_1):
        for col in range(width_1):
            lon_1, lat_1 = transform_elev1 * (col, row)
            lat_macico.append(lat_1)
            lon_macico.append(lon_1)
            elevation_1_list.append(elev_arr1[row, col])
            gravity_1_list.append(grav_arr1[row, col])
        
    # Loop for the second chunk Recorte)
    for row in range(height_2):
        for col in range(width_2):
            lon_2, lat_2 = transform_elev2 * (col, row)
            latitude_2.append(lat_2)
            longitude_2.append(lon_2)
            elevation_2_list.append(elev_arr2[row, col])
            gravity_2_list.append(grav_arr2[row, col])

    # Assigning Maciço's DataFrame   
    df_macico = pd.DataFrame({
        'Latitude_Maciço': lat_macico,
        'Longitude_Maciço': lon_macico,
        'Elevation_Maciço': elevation_1_list,
        'Gravity_Maciço': gravity_1_list
    })

    # Assigning Recorte's DataFrame
    df_recorte = pd.DataFrame({
        'Latitude_Recorte': latitude_2,
        'Longitude_Recorte': longitude_2,
        'Elevation_Recorte': elevation_2_list,
        'Gravity_Recorte': gravity_2_list
    })
    
    return df_macico, df_recorte

# Defining Filepaths
elevation_1_file = r'C:\Users\lzlag\Documents\Maciços Alcalinos (Bathymetry).tif'
elevation_2_file = r'C:\Users\lzlag\Documents\Recorte Maciços (Bathymetry).tif'
gravity_1_file = r'C:\Users\lzlag\Documents\Maciços Alcalinos (Free-Air).tif'
gravity_2_file = r'C:\Users\lzlag\Documents\Recorte Maciços (Free-Air).tif'

# Correct function call with four file paths
df_macico, df_recorte = tiff_to_dataframe(elevation_1_file, elevation_2_file, gravity_1_file, gravity_2_file)

# Applyig the projection for the Maciço chunk
input_crs = 'EPSG:4326'
crs_custom_maciço, proj_coords_macico = geographic2projected(
    input_crs, 
    [df_macico['Latitude_Maciço'].values, df_macico['Longitude_Maciço'].values]
)
# Adding the Easting/Northing coordinates to the DataFrame
df_macico = df_macico.assign(Easting=proj_coords_macico[0], Northing=proj_coords_macico[1])

# Applying the projection for the Recorte chunk
crs_custom_recorte, proj_coords_recorte = geographic2projected(
    input_crs, 
    [df_recorte['Latitude_Recorte'].values, df_recorte['Longitude_Recorte'].values]
)
# Adding the Easting/Northing coordinates to the DataFrame
df_recorte = df_recorte.assign(Easting=proj_coords_recorte[0], Northing=proj_coords_recorte[1])

# Reading the Topography File 
topography_1_file = r'C:\Users\lzlag\Documents\Maciços Alcalinos (Bathymetry).tif'
topography_2_file = r'C:\Users\lzlag\Documents\Recorte Maciços (Bathymetry).tif'

with rasterio.open(topography_1_file) as src:
    data_topo_1 = src.read(1)
    lon_min, lat_min, lon_max, lat_max = src.bounds
    lon_res = (lon_max - lon_min) / src.width
    lat_res = (lat_max - lat_min) / src.height
    lons_topo1 = np.linspace(lon_min + lon_res / 2, lon_max - lon_res /2, src.width)
    lat_topo1 = np.linspace(lat_min + lat_res / 2, lat_max - lat_res /2, src.height)

# Creating a Topography Dataset for the Macico's chunk
ds_topo_1 = xr.Dataset(
    {
        'bedrock_maciço':(['latitude', 'longitude'], data_topo_1)
    },
    coords = {
        'longitude': lons_topo1,
        'latitude': lat_topo1
    }
)

with rasterio.open(topography_2_file) as src:
    data_topo_2 = src.read(1)
    lon_min, lat_min, lon_max, lat_max = src.bounds
    lon_res2 = (lon_max - lon_min) / src.width
    lat_res2 = (lat_max - lat_min) / src.height
    lons_topo2 = np.linspace(lon_min + lon_res2 / 2, lon_max - lon_res2 / 2, src.width)
    lat_topo2 = np.linspace(lat_min + lat_res2 / 2, lat_max - lat_res2 / 2, src.height)

# Creating a Datase fot the Recorte's chunk
ds_topo_2 = xr.Dataset(

    {
        'bedrock_recorte':(['latitude', 'longitude'], data_topo_2)
    },
    coords ={
        'longitude': lons_topo2,
        'latitude': lat_topo2
    }
)

# Creating a DataArray for the Maciço's grid
grid_maciço = xr.DataArray(
    ds_topo_1.bedrock_maciço.values,
    coords ={'latitude': lat_topo1, 'longitude': lons_topo1},
    dims =['latitude', 'longitude']
)

# Creating a DataArray for the Recorte's grid
grid_recorte = xr.DataArray(
    ds_topo_2.bedrock_recorte.values,
    coords = {'latitude': lat_topo2, 'longitude': lons_topo2},
    dims = ['latitude', 'longitude']
)

# Projecting the topography to plain coordinate
transformer = Transformer.from_crs("EPSG:4326", crs_custom_maciço, always_xy=True)

# Defining a correct inverse projection
def proj_func(lon, lat, inverse=False):
    if inverse:
        return transformer.transform(lon, lat, direction=TransformDirection.INVERSE)
    else:
        return transformer.transform (lon, lat)

# Reprojecting the grid 
topo_plain_maciço = vd.project_grid(grid_maciço, projection=proj_func)
topo_plain_recorte = vd.project_grid(grid_recorte, projection= proj_func)

# Modelling the topography using prisms
prism_center_maciço = (topo_plain_maciço.easting, topo_plain_maciço.northing)
surface = topo_plain_maciço.values
# Define the density for maciço
density_maciço = np.where(topo_plain_maciço >= 0, 2570, 1040 - 2670)
topo_prisms_maciço = hm.prism_layer(
    prism_center_maciço,
    surface = surface,
    reference = 0,
    properties ={'density': density_maciço}
)

prism_center_recorte =(topo_plain_recorte.easting, topo_plain_recorte.northing)
surface = topo_plain_recorte.values
# Define the density for Recorte
density_recorte = np.where(topo_plain_recorte >= 0, 2670, 1040 - 2670)
topo_prism_recorte = hm.prism_layer(
    prism_center_recorte,
    surface=surface,
    reference=0,
    properties={'density': density_recorte}
)

# Computing the gravity effect of the Maciço's chunk
coordinates_maciço = (df_macico['Easting'].values, df_macico['Northing'].values, df_macico['Elevation_Maciço'].values)
result_maciço = topo_prisms_maciço.prism_layer.gravity(coordinates_maciço, field="g_z")

# Computiing the gravity effect of the Recorte's chunk
coordinates_recorte = (df_recorte['Easting'].values, df_recorte['Northing'].values, df_recorte['Elevation_Recorte'].values)
result_recorte = topo_prism_recorte.prism_layer.gravity(coordinates_recorte, field="g_z")

# Computing the Bouguer disturbance for the Maciço's chunk
maciços_Bouguer = df_macico['Gravity_Maciço'].values - result_maciço

# Computing the Bouguer disturbance for the Recorte's chunk
recorte_Bouguer = df_recorte['Gravity_Recorte'].values - result_recorte

# Adding the Bouguer Values to each DataFrame
df_macico['Bouguer'] = maciços_Bouguer
df_recorte['Bouguer'] = recorte_Bouguer

# Clearing NaN values before defining the Hyperparameters
df_macico.dropna(subset=['Easting', 'Northing', 'Elevation_Maciço', 'Bouguer'], inplace=True)
df_recorte.dropna(subset=['Easting', 'Northing', 'Elevation_Recorte', 'Bouguer'], inplace=True)

# Updating the Macicos Dataframe with the clean coordinates values
coordinates_maciço = (
    df_macico['Easting'].values,
    df_macico['Northing'].values,
    df_macico['Elevation_Maciço'].values
)

# Updating the Recorte Dataframe with the clean coordinates values
coordinates_recorte = (
    df_recorte['Easting'].values,
    df_recorte['Northing'].values,
    df_recorte['Elevation_Recorte'].values
)

# Setting up the HyperParameters to adjutst the Maciço's Bouguer values 
maciços_first_guess = hm.EquivalentSources(depth=1, damping=1)
maciços_first_guess.fit(coordinates_maciço, df_macico['Bouguer'].values)

score_maciços_first_guess = np.mean(
    vd.cross_val_score(
        maciços_first_guess,
        coordinates_maciço,
        df_macico['Bouguer'].values,
    )
)

dampings = [0.001, 0.001, 0.1, 1, 10, 100, 1000]
depths = [1e3, 2e3, 5e3, 10e3, 20e3, 50e3, 100e3]

# Estimating the Hyperparameters
maciços_parameters = [
    dict(damping =combo[0], depth=combo[1])
    for combo in itertools.product(dampings, depths)
]

maciço_equivalent_sources = hm.EquivalentSources()
scores = []
for parameters in maciços_parameters:
    model_macico = hm.EquivalentSources(**parameters)
    score = np.mean(
        vd.cross_val_score(
            model_macico,
            coordinates_maciço,
            df_macico['Bouguer'].values
        )
    )
    scores.append(score)
best_1 = np.argmax(scores)

# Optional: Printing the results
print("Best score:", scores[best_1])
print("Score with defaults:", score_maciços_first_guess)
print("Best Parameters:", maciços_parameters[best_1])

macicos_best = hm.EquivalentSources(**maciços_parameters[best_1]).fit(
    coordinates_maciço, df_macico['Bouguer'].values
)

# Setting up the HyperParameters to adjutst the Recorte's Bouguer values 
recorte_first_guess = hm.EquivalentSources(depth=1, damping=1)
recorte_first_guess.fit(coordinates_recorte, df_recorte['Bouguer'].values)

scores_recorte_first_guess = np.mean(
    vd.cross_val_score(
        recorte_first_guess,
        coordinates_recorte,
        df_recorte['Bouguer'].values,
    )
)

dampings = [0.001, 0.001, 0.1, 1, 10, 100, 1000]
depths = [1e3, 2e3, 5e3, 10e3, 20e3, 50e3, 100e3]

# Estimating the Hyperparameters
recorte_parameters = [
    dict(damping =combo[0], depth=combo[1])
    for combo in itertools.product(dampings, depths)
]

recorte_equivalent_sources = hm.EquivalentSources()
scores_recorte = []
for parameters in recorte_parameters:
    model_recorte = hm.EquivalentSources(**parameters)
    score = np.mean(
        vd.cross_val_score(
            model_recorte,
            coordinates_recorte,
            df_recorte['Bouguer'].values
        )
    )
    scores_recorte.append(score)
best_2 = np.argmax(scores_recorte)

# Optional: Printing the results    
print("Best score:", scores_recorte[best_2])
print("Score with defaults:", scores_recorte_first_guess)
print("Best Parameters:", recorte_parameters[best_2])

recorte_best = hm.EquivalentSources(**recorte_parameters[best_2]).fit(
    coordinates_recorte, df_recorte['Bouguer'].values
)

# Creating the Macico's regular grid
macicos_region = vd.get_region(coordinates_maciço)
macicos_grid_coords = vd.grid_coordinates(
    region=macicos_region,
    spacing=2e3,
    extra_coords=2.7e3
)
macicos_grid_bouguer = macicos_best.grid(macicos_grid_coords, data_names=['Bouguer'])

# Creating the Recorte's regular grid
recorte_region = vd.get_region(coordinates_recorte)
recorte_grid_coords = vd.grid_coordinates(
    region=recorte_region,
    spacing=2e3,
    extra_coords=2.7e3
)
recorte_grid_bouguer = recorte_best.grid(recorte_grid_coords, data_names=['Bouguer'])

# Plotting the Bouguer Anomaly for the Maciço's chunk
macicos_grid_bouguer.Bouguer.plot()
plt.gca().invert_yaxis()
plt.gca().set_aspect('equal')
plt.show()

# Plotting the Bouguer Anomaly for the Recorte's chunk
recorte_grid_bouguer.Bouguer.plot()
plt.gca().invert_yaxis()
plt.gca().set_aspect('equal')
plt.show()

# Exporting the Macico's result to a TIFF file
output_file_prefix = "Macico's Bouguer Anomaly_v01"
spacing = 100
macicos_grid_bouguer = macicos_grid_bouguer.drop_vars(["upward"], errors="ignore").rename({"easting": "x", "northing": "y"})
macicos_grid_bouguer.rio.write_crs(crs_custom_maciço, inplace=True)

# Writing each data variable to a separate TIFF file
for var in macicos_grid_bouguer.data_vars:
    # Extracting the DataArray
    macico_da= macicos_grid_bouguer[var]
    macico_da_ds = macico_da.to_dataset(name=var)
    macico_da_ds.rio.write_crs(crs_custom_maciço, inplace=True)
    macico_da_ds.rio.to_raster(f"{output_file_prefix}_{var}_spacing{spacing}.tif")
# Exporting the Maciço's result to a NetCDF file
macicos_grid_bouguer = macicos_grid_bouguer.reindex(latitude=list(reversed(macicos_grid_bouguer.y)))
macicos_grid_bouguer.rio.set_spatial_dims(x_dim="x", y_dim="y", inplace=True)
macicos_grid_bouguer.rio.write_coordinate_system(inplace=True).to_netcdf(
    f"{output_file_prefix}_spacing{spacing}.nc"
)

# Exporting the Recorte's result to a TIFF file
output_file_prefix = "Recorte's Bouguer Anomaly_v01"
spacing = 100
recorte_grid_bouguer = recorte_grid_bouguer.drop_vars(["upward"], errors="ignore").rename({"easting": "x", "northing": "y"})
recorte_grid_bouguer.rio.write_crs(crs_custom_recorte, inplace=True)\

# Writing each data variable to a separate TIFF file
for var in recorte_grid_bouguer.data_vars:
    # Extracting the DataArray
    recorte_da= recorte_grid_bouguer[var]
    recorte_da_ds = recorte_da.to_dataset(name=var)
    recorte_da_ds.rio.write_crs(crs_custom_recorte, inplace=True)
    recorte_da_ds.rio.to_raster(f"{output_file_prefix}_{var}_spacing{spacing}.tif")
# Exporting the Recorte's result to a NetCDF file
recorte_grid_bouguer = recorte_grid_bouguer.reindex(latitude=list(reversed(recorte_grid_bouguer.y)))
recorte_grid_bouguer.rio.set_spatial_dims(x_dim="x", y_dim="y", inplace=True)
recorte_grid_bouguer.rio.write_coordinate_system(inplace=True).to_netcdf(
    f"{output_file_prefix}_spacing{spacing}.nc"
)

